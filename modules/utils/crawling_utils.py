# modules/utils/crawling_utils.py

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
from .web_driver import get_driver
from .logger import setup_logger
from config.settings import API_TIMEOUT

logger = setup_logger("crawling_utils")


def fetch_with_selenium(url: str, selector: str, attribute: str = "text", timeout: int = 10):
    """ğŸ•·ï¸ Seleniumì„ ì‚¬ìš©í•œ í¬ë¡¤ë§"""
    driver = get_driver()
    if not driver:
        logger.error("âŒ WebDriver ì´ˆê¸°í™” ì‹¤íŒ¨")
        return []

    logger.info(f"ğŸŒ URL ìš”ì²­ ì¤‘: {url}")
    try:
        driver.get(url)
        WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
        elements = driver.find_elements(By.CSS_SELECTOR, selector)
        data = [e.get_attribute("href") if attribute == "href" else e.text for e in elements]
        logger.info(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
        return data
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        return []
    finally:
        driver.quit()


def fetch_with_api(url: str, params: dict = None, method: str = "GET", timeout: int = API_TIMEOUT):
    """ğŸ”— API ìš”ì²­"""
    logger.info(f"ğŸ”— API ìš”ì²­ ì¤‘: {url} | íŒŒë¼ë¯¸í„°: {params}")
    try:
        response = requests.request(method, url, params=params, timeout=timeout)
        response.raise_for_status()
        logger.info("âœ… API ìš”ì²­ ì„±ê³µ")
        return response.json()
    except requests.RequestException as e:
        logger.error(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None
