# modules/crawlers/swisstarget_crawler.py

from modules.utils import fetch_with_api, save_data, setup_logger
from modules.constants import SWISSTARGET_URL
from config.settings import SWISSTARGET_RAW_DIR, FILENAME_RULES

logger = setup_logger("swisstarget_crawler")

def crawl_swisstarget(herb_name, smiles_list):
    """
    ğŸ¯ SwissTargetPrediction í¬ë¡¤ë§ (SMILES ê¸°ë°˜)
    Args:
        herb_name (str): ì•½ì¬ ì´ë¦„
        smiles_list (list): SMILES ëª©ë¡
    """
    logger.info(f"ğŸš€ {herb_name}: SwissTargetPrediction í¬ë¡¤ë§ ì‹œì‘ ({len(smiles_list)}ê°œ SMILES)")

    results = []
    for smiles in smiles_list:
        response = fetch_with_api(SWISSTARGET_URL, params={"smiles": smiles})
        if response:
            results.append({"smiles": smiles, "predictions": response})
        else:
            logger.warning(f"âš ï¸ {smiles}: ì˜ˆì¸¡ ì‹¤íŒ¨")

    file_name = FILENAME_RULES["swisstarget_results"].format(herb_name=herb_name)
    save_data(results, file_name, subdir=SWISSTARGET_RAW_DIR)
    logger.info(f"âœ… {herb_name}: SwissTargetPrediction ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {file_name}")
