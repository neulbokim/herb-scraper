# modules/crawlers/herb_crawler.py

from modules.constants.herbs import HERB_URLS
from modules.utils import fetch_with_selenium, save_to_json, setup_logger
from config.settings import HERB_RAW_DIR
from pathlib import Path
import time

logger = setup_logger("herb_crawler")

def crawl_ingredient_details(driver, ingredient_url: str) -> dict:
    """ğŸ” ì„±ë¶„ ìƒì„¸ í˜ì´ì§€ì—ì„œ Molecule Smile ë° Related Gene Targets ì¶”ì¶œ"""
    base_url = "http://herb.ac.cn"
    full_url = f"{base_url}{ingredient_url}"
    logger.info(f"ğŸ”— ì„±ë¶„ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§: {full_url}")

    driver.get(full_url)
    time.sleep(2)

    try:
        smile_element = driver.find_element("xpath", "//b[contains(text(), 'Molecule smile')]/following-sibling::span")
        molecule_smile = smile_element.text.strip()
    except Exception:
        molecule_smile = None
        logger.warning("âš ï¸ Molecule smile ì •ë³´ ì—†ìŒ")

    try:
        target_elements = driver.find_elements("xpath", "//h4[contains(text(), 'Related Gene Targets')]/following-sibling::div//li")
        gene_targets = [target.text.strip() for target in target_elements]
    except Exception:
        gene_targets = []
        logger.warning("âš ï¸ Related Gene Targets ì •ë³´ ì—†ìŒ")

    return {
        "molecule_smile": molecule_smile,
        "related_gene_targets": gene_targets
    }

def crawl_herb_data(herbs: list):
    """ğŸŒ¿ HERB í¬ë¡¤ë§: ì•½ì¬ë³„ í™œì„± ì„±ë¶„ ë° íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ ìˆ˜ì§‘"""
    from modules.utils.web_driver import get_driver

    driver = get_driver(headless=True)

    for herb in herbs:
        herb_url = HERB_URLS.get(herb)
        if not herb_url:
            logger.error(f"âŒ {herb}: HERB URL ì—†ìŒ")
            continue

        logger.info(f"ğŸš€ {herb}: í¬ë¡¤ë§ ì‹œì‘ â†’ {herb_url}")
        driver.get(herb_url)
        time.sleep(2)

        try:
            ingredient_rows = driver.find_elements("xpath", "//tbody[@class='ant-table-tbody']/tr")
            ingredients = []

            for row in ingredient_rows:
                cells = row.find_elements("tag name", "td")
                if len(cells) >= 3:
                    ingredient_id = cells[0].find_element("tag name", "a").get_attribute("href")
                    ingredient_name = cells[1].text.strip()
                    ingredient_alias = cells[2].text.strip()

                    details = crawl_ingredient_details(driver, ingredient_id)

                    ingredients.append({
                        "ingredient_id": ingredient_id.split("=")[-1],
                        "ingredient_name": ingredient_name,
                        "ingredient_alias": ingredient_alias,
                        "molecule_smile": details["molecule_smile"],
                        "related_gene_targets": details["related_gene_targets"]
                    })

            output_dir = Path(HERB_RAW_DIR)
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"herb_ingredient_urls_{herb}.json"
            save_to_json(ingredients, output_path)
            logger.info(f"âœ… {herb}: {len(ingredients)}ê°œ ì„±ë¶„ ìˆ˜ì§‘ ì™„ë£Œ â†’ {output_path}")

        except Exception as e:
            logger.error(f"âŒ {herb}: í¬ë¡¤ë§ ì‹¤íŒ¨ - {e}")

    driver.quit()