# scripts/main.py

import argparse
import time
from scripts.crawlers import (
    crawl_herb_data,
    crawl_swissadme,
    crawl_batman_tcm,
    crawl_swisstarget,
    crawl_tcmsp
)
from scripts.preprocess import (
    filter_active_compounds,
    merge_herb_data
)
from scripts.converters import (
    convert_json_to_csv,
    convert_json_to_xlsx,
    convert_csv_to_json
)
from modules.utils import setup_logger

logger = setup_logger("main_pipeline")


def run_step(step_name, function, *args, **kwargs):
    """ğŸš¦ ê³µí†µ ë‹¨ê³„ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info(f"ğŸš€ [{step_name}] ì‹œì‘")
    start_time = time.time()

    try:
        function(*args, **kwargs)
        elapsed = time.time() - start_time
        logger.info(f"âœ… [{step_name}] ì™„ë£Œ (â±ï¸ {elapsed:.2f}s)")
    except Exception as e:
        logger.error(f"âŒ [{step_name}] ì‹¤íŒ¨: {e}")


def run_pipeline(args):
    """ğŸŒ± ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""

    if args.crawl:
        run_step("HERB í¬ë¡¤ë§", crawl_herb_data)
        run_step("SwissADME í¬ë¡¤ë§", crawl_swissadme)
        run_step("BATMAN-TCM API í˜¸ì¶œ", crawl_batman_tcm)
        run_step("SwissTargetPrediction í¬ë¡¤ë§", crawl_swisstarget)
        run_step("TCMSP í¬ë¡¤ë§", crawl_tcmsp)

    if args.preprocess:
        run_step("í™œì„± ì„±ë¶„ í•„í„°ë§", filter_active_compounds)
        run_step("ë°ì´í„° ë³‘í•©", merge_herb_data)

    if args.convert:
        run_step("JSON â†’ CSV ë³€í™˜", convert_json_to_csv)
        run_step("JSON â†’ XLSX ë³€í™˜", convert_json_to_xlsx)
        run_step("CSV â†’ JSON ë³€í™˜", convert_csv_to_json)

    logger.info("ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")


def main():
    parser = argparse.ArgumentParser(description="ğŸŒ¿ HERB-SCRAPER ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    parser.add_argument(
        "--crawl", action="store_true", help="ğŸ•·ï¸ í¬ë¡¤ë§ ë‹¨ê³„ ì‹¤í–‰"
    )
    parser.add_argument(
        "--preprocess", action="store_true", help="ğŸ§¹ ì „ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰"
    )
    parser.add_argument(
        "--convert", action="store_true", help="ğŸ”„ ë°ì´í„° ë³€í™˜ ë‹¨ê³„ ì‹¤í–‰"
    )

    args = parser.parse_args()

    if not (args.crawl or args.preprocess or args.convert):
        logger.warning("âš ï¸ ì‹¤í–‰í•  ë‹¨ê³„ë¥¼ ì„ íƒí•˜ì„¸ìš”: --crawl, --preprocess, --convert")
        return

    run_pipeline(args)


if __name__ == "__main__":
    main()
